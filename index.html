<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sripriya Reddy | Data Engineer Portfolio</title>
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap" rel="stylesheet">
</head>

<body>

    <header class="hero">
        <div class="container">
            <h1 class="hero-title">Sripriya Reddy</h1>
            <h2 class="hero-subtitle">Data Engineer</h2>
            <p class="hero-summary">
                Data Engineer with 5+ years of experience architecting and optimizing data ecosystems. Proficient in
                designing ETL frameworks, orchestrating large-scale data integrations, and implementing advanced data
                modeling techniques to support high-impact analytics.
            </p>
            <div class="hero-contact">
                <a href="mailto:sripriyaareddy20@gmail.com" class="contact-link">Email</a>
                <span class="separator">|</span>
                <a href="tel:+19724138713" class="contact-link">+1 (972) 413-8713</a>
                <span class="separator">|</span>
                <a href="https://www.linkedin.com/in/sripriya-reddy20/" target="_blank"
                    class="contact-link">LinkedIn</a>
                <span class="separator">|</span>
                <a href="https://github.com/sripriyareddy20" target="_blank" class="contact-link">GitHub</a>
            </div>
        </div>
    </header>

    <main>
        <section id="skills" class="skills-section">
            <div class="container">
                <h2 class="section-title">Technical Skills</h2>
                <div class="skills-grid">
                    <div class="skill-category">
                        <h3>Programming & Scripting</h3>
                        <p>Python, Java, Scala, SQL, JavaScript, Bash/Shell Scripting, DAX</p>
                    </div>
                    <div class="skill-category">
                        <h3>Big Data Technologies</h3>
                        <p>Hadoop, Apache Spark, Hive, Kafka, Flume, HBase</p>
                    </div>
                    <div class="skill-category">
                        <h3>Cloud Platforms (AWS, GCP)</h3>
                        <p>AWS (S3, Redshift, Lambda, EC2, Glue, Kinesis), GCP (BigQuery, Cloud Functions, Dataflow,
                            Pub/Sub), Azure</p>
                    </div>
                    <div class="skill-category">
                        <h3>Databases & Storage</h3>
                        <p>MySQL, PostgreSQL, MongoDB, Cassandra, Oracle DB</p>
                    </div>
                    <div class="skill-category">
                        <h3>ETL & Data Integration</h3>
                        <p>Apache Airflow, Informatica, Talend, dbt, Alteryx</p>
                    </div>
                    <div class="skill-category">
                        <h3>Containerization & DevOps</h3>
                        <p>Docker, Kubernetes (EKS/GKE), Terraform, GitLab CI/CD, Jenkins, Openshift</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="experience" class="experience-section">
            <div class="container">
                <h2 class="section-title">Professional Experience</h2>
                <div class="experience-grid">
                    <article class="job-card">
                        <div class="job-header">
                            <h3 class="job-title">Data Engineer</h3>
                            <p class="job-company">Charles Schwab | TX, USA</p>
                            <p class="job-date">Dec 2024 - Present</p>
                        </div>
                        <p class="job-summary">
                            Architecting high-throughput data systems in a critical financial environment. Focused on
                            modernizing data infrastructure to support real-time analytics, ensure data quality, and
                            drive operational efficiency for trading and settlement platforms.
                        </p>
                        <ul class="job-duties">
                            <li>Orchestrated the deployment of 14 ETL workflows using AWS Glue and Spark, accelerating
                                daily transaction data processing by 38% for analytics and compliance teams.</li>
                            <li>Engineered real-time streaming pipelines using Kafka and Kinesis to process over 2.5M
                                daily trade events with sub-2-second latency for fraud detection and risk analytics.
                            </li>
                            <li>Led the migration of 8 TB of historical market data to AWS Redshift, slashing query
                                response times by 75% (from 12 seconds to under 3) and boosting analyst productivity.
                            </li>
                            <li>Automated over 50 data quality validation checks in Airflow, cutting data load failures
                                by 92% and reducing incident resolution times from 6 hours to less than 1 hour.</li>
                        </ul>
                    </article>
                    <article class="job-card">
                        <div class="job-header">
                            <h3 class="job-title">Data Engineer</h3>
                            <p class="job-company">Tata Consultancy Services | India</p>
                            <p class="job-date">May 2022 - May 2023</p>
                        </div>
                        <p class="job-summary">
                            Delivered enterprise-scale data solutions for major banking clients. Specialized in building
                            robust data integration pipelines, optimizing data warehouse performance, and implementing
                            automation to improve reporting workflows.
                        </p>
                        <ul class="job-duties">
                            <li>Improved Power BI dashboard refresh speeds by 72% (from 25 to 7 minutes) by designing
                                and implementing an optimized 18-dimension data warehouse schema for retail banking
                                analytics.</li>
                            <li>Cut mission-critical data pipeline runtimes by over 60% (from 9 to 3.5 hours) by
                                re-architecting and configuring Spark jobs for distributed parallel processing.</li>
                            <li>Eliminated over 80 manual hours per month by automating GCP Cloud Composer workflows for
                                12 different data sources, ensuring timely delivery for enterprise reporting.</li>
                            <li>Reduced manual data reconciliation time by 65% for financial reporting workflows by
                                building over 20 automated integration pipelines with Apache NiFi and Talend.</li>
                        </ul>
                    </article>
                    <article class="job-card">
                        <div class="job-header">
                            <h3 class="job-title">Data Analyst</h3>
                            <p class="job-company">Capgemini | India</p>
                            <p class="job-date">Jun 2019 - May 2022</p>
                        </div>
                        <p class="job-summary">
                            Translated complex data into actionable business intelligence for high-profile telecom and
                            retail clients. Focused on optimizing SQL queries, automating reporting, and creating
                            intuitive visualizations to support executive decision-making.
                        </p>
                        <ul class="job-duties">
                            <li>Transformed reporting workflows by migrating 120 static Excel reports to interactive
                                Tableau dashboards, reducing preparation time from 4 hours to under 15 minutes.</li>
                            <li>Boosted report accessibility and performance by optimizing complex PostgreSQL queries
                                with advanced indexing, achieving an average 72% reduction in execution time.</li>
                            <li>Empowered over 200 end-users with self-service analytics by designing and implementing
                                OLAP cubes for multi-dimensional sales analysis.</li>
                            <li>Saved 25 hours of manual work each month by developing and deploying automated ingestion
                                scripts for seven disparate source systems.</li>
                        </ul>
                    </article>
                    <article class="job-card">
                        <div class="job-header">
                            <h3 class="job-title">Reporting Analyst</h3>
                            <p class="job-company">Adons Softech | India</p>
                            <p class="job-date">Jan 2019 - Apr 2019</p>
                        </div>
                        <p class="job-summary">
                            Developed foundational reporting solutions that significantly improved the speed and
                            accuracy of business insights. Automated manual processes and implemented data validation
                            checks to build trust in data and empower leadership.
                        </p>
                        <ul class="job-duties">
                            <li>Accelerated decision-making cycles by transforming reporting frequency from monthly to
                                weekly through the creation of 25 integrated Power BI dashboards.</li>
                            <li>Freed up 18 hours of analyst time weekly by automating complex Excel reporting workflows
                                using a combination of VBA and SQL queries.</li>
                            <li>Increased trust in business reports by creating validation processes that reduced data
                                discrepancies across 1,200+ KPIs by over 85%.</li>
                            <li>Streamlined data quality checks by designing SQL validation scripts that reduced manual
                                review effort by 60%.</li>
                        </ul>
                    </article>
                </div>
            </div>
        </section>

        <section id="projects" class="projects-section">
            <div class="container">
                <h2 class="section-title">Key Projects</h2>
                <div class="projects-grid">
                    <div class="project-card">
                        <h3>Financial Report Anomaly Detector</h3>
                        <p>Built a CNN-based anomaly detection pipeline using AWS Textract, OpenCV, and TensorFlow,
                            achieving 99.6% accuracy in detecting anomalies within scanned compliance documents.</p>
                    </div>
                    <div class="project-card">
                        <h3>Real-Time Fraud Detection System</h3>
                        <p>Designed a scalable fraud detection pipeline with AWS (S3, Lambda, Glue, Redshift) and Apache
                            Airflow, enhancing ingestion speed and improving real-time query performance.</p>
                    </div>
                    <div class="project-card">
                        <h3>Supply Chain Optimization</h3>
                        <p>Developed AWS- and Airflow-based pipelines to optimize inventory management and demand
                            forecasting for McDonald's across 100+ stores. Built interactive Power BI dashboards for
                            rapid decision-making.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="education-certs" class="education-certs-section">
            <div class="container">
                <div class="columns">
                    <div class="column">
                        <h2 class="section-title-small">Education</h2>
                        <div class="edu-item">
                            <h3>Master of Science in Information Systems and Technologies</h3>
                            <p>University of North Texas, Denton, Texas</p>
                        </div>
                        <div class="edu-item">
                            <h3>Bachelor of Science in Computer Science</h3>
                            <p>Raja Bahadur Venkata Rama Reddy Women's College, Hyderabad</p>
                        </div>
                    </div>
                    <div class="column">
                        <h2 class="section-title-small">Certifications</h2>
                        <ul>
                            <li>AWS Cloud Practitioner - Amazon</li>
                            <li>AWS Al Practitioner - Amazon</li>
                            <li>Fabric Data Engineer Associate DP-700-Microsoft</li>
                            <li>Generative Al Fundamentals - Databricks</li>
                            <li>Databricks Fundamentals - Databricks</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Sripriya Reddy. All Rights Reserved.</p>
        </div>
    </footer>

</body>

</html>